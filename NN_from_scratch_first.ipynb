{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cr√©ation de l'exemple XOR\n",
    "\n",
    "X = np.array([[0, 0],\n",
    "[0, 1],\n",
    "[1, 0],\n",
    "[1, 1]]).T\n",
    "\n",
    "y = np.array([0, 1, 1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def newdataset(nbr_of_examples):\n",
    "    X = np.random.randint(0, 2, size = (2, nbr_of_examples))\n",
    "\n",
    "    y = X.sum(axis=0, keepdims = True)    \n",
    "    y[y != 1] = 0\n",
    "    \n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = newdataset(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 4)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "class neuron_net:\n",
    "    \n",
    "    \n",
    "    def sigmoid (self, Z):\n",
    "    \n",
    "        A = 1 / (1+ np.exp(-Z))\n",
    "    \n",
    "        return A\n",
    "    \n",
    "    \n",
    "    def relu (self, Z):\n",
    "    \n",
    "        A = np.maximum(0,Z)\n",
    "    \n",
    "        return A\n",
    "    \n",
    "    \n",
    "    def relu_deriv (self, dA, Z):\n",
    "    \n",
    "        dZ = np.array(dA, copy = True)\n",
    "        dZ[Z <= 0] = 0\n",
    "        \n",
    "        return dZ\n",
    "    \n",
    "    \n",
    "    def sigmoid_deriv (self, dA, Z):\n",
    "        \n",
    "        s = self.sigmoid(Z)\n",
    "        dZ = dA * s * (1 - s)\n",
    "        \n",
    "        return dZ\n",
    "\n",
    "    \n",
    "    def __init__(self, list_of_parameters):\n",
    "        \n",
    "        self.num_layers = len(list_of_parameters)\n",
    "        \n",
    "        self.list_of_parameters = list_of_parameters\n",
    "        \n",
    "        #np.random.seed(1)\n",
    "        \n",
    "        parameters = {}\n",
    "        \n",
    "        for layer in range(1, self.num_layers):\n",
    "            \n",
    "            parameters[\"W\" + str(layer)] = np.random.randn(self.list_of_parameters[layer], self.list_of_parameters[layer - 1]) * np.sqrt(self.list_of_parameters[layer - 1])\n",
    "            \n",
    "            parameters[\"b\" + str(layer)] = np.zeros((self.list_of_parameters[layer], 1))\n",
    "            \n",
    "        \n",
    "        self.parameters = parameters\n",
    "        \n",
    "    \n",
    "    def fit (self, X):\n",
    "        \n",
    "        self.m = X.shape[1]\n",
    "        \n",
    "        caches = {}\n",
    "        \n",
    "        caches[\"A0\"] = X\n",
    "        \n",
    "        # relu n activations\n",
    "        \n",
    "        for layer in range(1, self.num_layers - 1):\n",
    "            \n",
    "            Z = np.dot(self.parameters[\"W\" + str(layer)], caches[\"A\" + str(layer - 1)]) + self.parameters[\"b\" + str(layer)]\n",
    "            A = self.relu(Z)\n",
    "            \n",
    "            caches[\"Z\" + str(layer)] = Z\n",
    "            caches[\"W\" + str(layer)] = self.parameters[\"W\" + str(layer)]\n",
    "            caches[\"b\" + str(layer)] = self.parameters[\"b\" + str(layer)]\n",
    "            caches[\"A\" + str(layer)] = A\n",
    "        \n",
    "        \n",
    "        # last sigmoid activation\n",
    "        \n",
    "        Z = np.dot(self.parameters[\"W\" + str(self.num_layers - 1)], Z) + self.parameters[\"b\" + str(self.num_layers - 1)]\n",
    "        A = self.sigmoid(Z)\n",
    "        \n",
    "        caches[\"Z\" + str(self.num_layers - 1)] = Z\n",
    "        caches[\"W\" + str(self.num_layers - 1)] = self.parameters[\"W\" + str(self.num_layers - 1)]\n",
    "        caches[\"b\" + str(self.num_layers - 1)] = self.parameters[\"b\" + str(self.num_layers - 1)]\n",
    "        caches[\"A\" + str(self.num_layers - 1)] = A\n",
    "        \n",
    "        self.caches = caches\n",
    "        \n",
    "        \n",
    "    def comupte_cost (self, y):\n",
    "        \n",
    "        cost = (1 / self.m) * (-np.dot(y, np.log(self.caches[\"A\" + str(self.num_layers - 1)]).T) - np.dot(1 - y, np.log(1 - self.caches[\"A\" + str(self.num_layers - 1)]).T))\n",
    "        \n",
    "        self.cost = np.squeeze(cost)\n",
    "        \n",
    "    \n",
    "    def backward (self, y):\n",
    "        \n",
    "        grads = {}\n",
    "        \n",
    "        lastLayer = self.num_layers - 1\n",
    "        \n",
    "        #sigmoid derivatives\n",
    "        \n",
    "        grads[\"dA\" + str(lastLayer)] = - (np.divide( y, self.caches[\"A\" + str(lastLayer)]) - np.divide( 1 - y, 1 - self.caches[\"A\" + str(lastLayer)]))\n",
    "        grads[\"dZ\" + str(lastLayer)] = self.sigmoid_deriv(grads[\"dA\" + str(lastLayer)], self.caches[\"Z\" + str(lastLayer)]) \n",
    "        grads[\"dW\" + str(lastLayer)] = np.dot(grads[\"dZ\" + str(lastLayer)], self.caches[\"A\" + str(lastLayer - 1)].T) / self.m\n",
    "        grads[\"db\" + str(lastLayer)] = np.sum(grads[\"dZ\" + str(lastLayer)], axis = 1, keepdims = True) / self.m\n",
    "        \n",
    "        \n",
    "        #relu n derivatives\n",
    "        \n",
    "        for l in reversed(range(1, self.num_layers - 1)):\n",
    "            \n",
    "            grads[\"dA\" + str(l)] = np.dot(self.caches[\"W\" + str(l + 1)].T, grads[\"dZ\" + str(l + 1)])\n",
    "            grads[\"dZ\" + str(l)] = self.relu_deriv(grads[\"dA\" + str(l)], self.caches[\"Z\" + str(l)])\n",
    "            grads[\"dW\" + str(l)] = np.dot(grads[\"dZ\" + str(l)], self.caches[\"A\" + str(l - 1)].T) / self.m\n",
    "            grads[\"db\" + str(l)] = np.sum(grads[\"dZ\" + str(l)], axis = 1, keepdims = True) / self.m\n",
    "        \n",
    "                                                \n",
    "        self.grads = grads\n",
    "        \n",
    "        \n",
    "    def update_param (self, learning_rate):\n",
    "        \n",
    "        for l in range(1, self.num_layers):\n",
    "            \n",
    "            self.parameters[\"W\" + str(l)] = self.parameters[\"W\" + str(l)] - learning_rate * self.grads[\"dW\" + str(l)]\n",
    "            self.parameters[\"b\" + str(l)] = self.parameters[\"b\" + str(l)] - learning_rate * self.grads[\"db\" + str(l)]\n",
    "    \n",
    "    \n",
    "    def train (self, X, y, learning_rate, num_iterations = 1000):\n",
    "        \n",
    "        cost_track = []\n",
    "        \n",
    "        for i in range(0, num_iterations):\n",
    "            \n",
    "            self.fit(X)\n",
    "            \n",
    "            self.comupte_cost(y)\n",
    "            \n",
    "            self.backward(y)\n",
    "            \n",
    "            self.update_param(learning_rate)\n",
    "            \n",
    "            if i % 100 == 0:\n",
    "                cost_track.append(self.cost)\n",
    "                print(\"Cost after %i iterations: %f\" % (i, self.cost))\n",
    "            \n",
    "        self.cost_track = cost_track\n",
    "        \n",
    "        \n",
    "    def predict (self, y):\n",
    "        \n",
    "        predictions = np.zeros((1,self.m))\n",
    "        \n",
    "        probability = self.caches[\"A\" + str(self.num_layers - 1)]\n",
    "        \n",
    "        for i in range(0, probability.shape[1]):\n",
    "            \n",
    "            if probability[0,i] > 0.5:\n",
    "                predictions[0,i] = 1\n",
    "            else:\n",
    "                predictions[0,i] = 0\n",
    "                \n",
    "        print (\"Accuracy: \" + str(np.sum((predictions == y) / self.m)))\n",
    "                \n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = neuron_net([2,4,2,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'W1': array([[ 1.18228921,  2.18263939],\n",
       "        [ 1.07311326,  1.25145005],\n",
       "        [-1.24066342, -1.22723646],\n",
       "        [-2.03770642,  1.74266901]]), 'b1': array([[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]]), 'W2': array([[-0.50835974,  2.79968788, -1.56382337, -0.87501797],\n",
       "        [ 0.19085017,  1.84290014,  0.12150039,  0.42224951]]), 'b2': array([[0.],\n",
       "        [0.]]), 'W3': array([[0.02337351, 0.25058128]]), 'b3': array([[0.]])}"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A0': array([[0, 0, 1, 1],\n",
       "        [0, 1, 0, 1]]),\n",
       " 'Z1': array([[ 0.        ,  2.18263939,  1.18228921,  3.3649286 ],\n",
       "        [ 0.        ,  1.25145005,  1.07311326,  2.3245633 ],\n",
       "        [ 0.        , -1.22723646, -1.24066342, -2.46789988],\n",
       "        [ 0.        ,  1.74266901, -2.03770642, -0.29503741]]),\n",
       " 'W1': array([[ 1.18228921,  2.18263939],\n",
       "        [ 1.07311326,  1.25145005],\n",
       "        [-1.24066342, -1.22723646],\n",
       "        [-2.03770642,  1.74266901]]),\n",
       " 'b1': array([[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]]),\n",
       " 'A1': array([[0.        , 2.18263939, 1.18228921, 3.3649286 ],\n",
       "        [0.        , 1.25145005, 1.07311326, 2.3245633 ],\n",
       "        [0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 1.74266901, 0.        , 0.        ]]),\n",
       " 'Z2': array([[0.        , 0.86923687, 2.40335395, 4.7974575 ],\n",
       "        [0.        , 3.4586957 , 2.20328067, 4.92613524]]),\n",
       " 'W2': array([[-0.50835974,  2.79968788, -1.56382337, -0.87501797],\n",
       "        [ 0.19085017,  1.84290014,  0.12150039,  0.42224951]]),\n",
       " 'b2': array([[0.],\n",
       "        [0.]]),\n",
       " 'A2': array([[0.        , 0.86923687, 2.40335395, 4.7974575 ],\n",
       "        [0.        , 3.4586957 , 2.20328067, 4.92613524]]),\n",
       " 'Z3': array([[0.        , 0.8870015 , 0.6082757 , 1.34653068]]),\n",
       " 'W3': array([[0.02337351, 0.25058128]]),\n",
       " 'b3': array([[0.]]),\n",
       " 'A3': array([[0.5       , 0.708271  , 0.64754737, 0.79356186]])}"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.caches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.comupte_cost(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0.76259837)"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.backward(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dA3': array([[ 2.        , -1.41188895, -1.54428858,  4.84406607]]),\n",
       " 'dZ3': array([[ 0.5       , -0.291729  , -0.35245263,  0.79356186]]),\n",
       " 'dW3': array([[0.67660731, 0.53090978]]),\n",
       " 'db3': array([[0.16234506]]),\n",
       " 'dA2': array([[ 0.01168675, -0.00681873, -0.00823806,  0.01854833],\n",
       "        [ 0.12529064, -0.07310183, -0.08831803,  0.19885174]]),\n",
       " 'dZ2': array([[ 0.        , -0.00681873, -0.00823806,  0.01854833],\n",
       "        [ 0.        , -0.07310183, -0.08831803,  0.19885174]]),\n",
       " 'dW2': array([[ 0.0094478 ,  0.00643577,  0.        , -0.0029707 ],\n",
       "        [ 0.10128739,  0.06899623,  0.        , -0.03184807]]),\n",
       " 'db2': array([[0.00087289],\n",
       "        [0.00935797]]),\n",
       " 'dA1': array([[ 0.        , -0.01048513, -0.01266762,  0.02852167],\n",
       "        [ 0.        , -0.15380968, -0.18582529,  0.41839343],\n",
       "        [ 0.        ,  0.00178139,  0.00215219, -0.00484574],\n",
       "        [ 0.        , -0.0249007 , -0.0300838 ,  0.06773493]]),\n",
       " 'dZ1': array([[ 0.        , -0.01048513, -0.01266762,  0.02852167],\n",
       "        [ 0.        , -0.15380968, -0.18582529,  0.41839343],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        , -0.0249007 ,  0.        ,  0.        ]]),\n",
       " 'dW1': array([[ 0.00396351,  0.00450913],\n",
       "        [ 0.05814203,  0.06614594],\n",
       "        [ 0.        ,  0.        ],\n",
       "        [ 0.        , -0.00622517]]),\n",
       " 'db1': array([[ 0.00134223],\n",
       "        [ 0.01968961],\n",
       "        [ 0.        ],\n",
       "        [-0.00622517]])}"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.update_param(0.0075)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after 0 iterations: 0.210254\n",
      "Cost after 100 iterations: 0.201255\n",
      "Cost after 200 iterations: 0.193623\n",
      "Cost after 300 iterations: 0.185761\n",
      "Cost after 400 iterations: 0.177718\n",
      "Cost after 500 iterations: 0.170396\n",
      "Cost after 600 iterations: 0.163879\n",
      "Cost after 700 iterations: 0.157324\n",
      "Cost after 800 iterations: 0.151600\n",
      "Cost after 900 iterations: 0.145117\n",
      "Cost after 1000 iterations: 0.139465\n",
      "Cost after 1100 iterations: 0.134681\n",
      "Cost after 1200 iterations: 0.129166\n",
      "Cost after 1300 iterations: 0.124529\n",
      "Cost after 1400 iterations: 0.119968\n",
      "Cost after 1500 iterations: 0.116212\n",
      "Cost after 1600 iterations: 0.111794\n",
      "Cost after 1700 iterations: 0.108181\n",
      "Cost after 1800 iterations: 0.104652\n",
      "Cost after 1900 iterations: 0.100634\n",
      "Cost after 2000 iterations: 0.097308\n",
      "Cost after 2100 iterations: 0.094631\n",
      "Cost after 2200 iterations: 0.091512\n",
      "Cost after 2300 iterations: 0.088427\n",
      "Cost after 2400 iterations: 0.085992\n",
      "Cost after 2500 iterations: 0.083668\n",
      "Cost after 2600 iterations: 0.080806\n",
      "Cost after 2700 iterations: 0.078555\n",
      "Cost after 2800 iterations: 0.076386\n",
      "Cost after 2900 iterations: 0.074276\n"
     ]
    }
   ],
   "source": [
    "nn.train(X,y,0.009, 3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 1., 0.]])"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.predict(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
